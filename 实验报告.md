# Pintos1
组员：修宇婷 马静雯 杨瑷彤 陈爽 聂小禹  
学号：16281051 16281046 16281053 16281032 16281012

问题1 重新实现timer_sleep函数
---
1.1分析原有的Timer_sleep函数  
---
  timer_sleep函数在devices/timer.c。系统现在是使用busy wait实现的，即线程不停地循环，直到时间片耗尽。逐句阅读之后发现timer_sleep就是在ticks时间内， 如果线程处于running状态就不断把他扔到就绪队列不让他执行。它的缺点是线程依然不断在cpu就绪队列和running队列之间来回， 占用了cpu资源，而我们希望用一种唤醒机制来实现这个函数。  
  
1.2重新实现timer_sleep函数的原理
---

调用timer_sleep的时候直接把线程阻塞掉，然后给线程结构体加一个成员ticks_blocked来记录这个线程被sleep了多少时间， 然后利用操作系统自身的时钟中断（每个tick会执行一次）加入对线程状态的检测， 每次检测将ticks_blocked减1, 如果减到0就唤醒这个线程。

1.3具体代码
---
```
/* Sleeps for approximately TICKS timer ticks.  Interrupts must
   be turned on. */
void
timer_sleep (int64_t ticks)
{
  if (ticks <= 0)
  {
    return;
  }
  ASSERT (intr_get_level () == INTR_ON);
  enum intr_level old_level = intr_disable ();
  struct thread *current_thread = thread_current ();
  current_thread->ticks_blocked = ticks;
  thread_block ();
  intr_set_level (old_level);
}

/* Puts the current thread to sleep.  It will not be scheduled
   again until awoken by thread_unblock().

   This function must be called with interrupts turned off.  It
   is usually a better idea to use one of the synchronization
   primitives in synch.h. */
void
thread_block (void)
{
  ASSERT (!intr_context ());
  ASSERT (intr_get_level () == INTR_OFF);

  thread_current ()->status = THREAD_BLOCKED;
  schedule ();
}
```
1.4实验步骤
---
给线程的结构体加上我们的ticks_blocked成员，然后在线程被创建的时候初始化ticks_blocked为0， 加在thread_create函数内。然后修改时钟中断处理函数， 加入线程sleep时间的检测， 加在timer_interrupt内。
```
/* Record the time the thread has been blocked. */
int64_t ticks_blocked;

t->ticks_blocked = 0;

thread_foreach (blocked_thread_check, NULL);
```
这里的thread_foreach就是对每个线程都执行blocked_thread_check这个函数。
```
/* Invoke function 'func' on all threads, passing along 'aux'.
   This function must be called with interrupts off. */
void
thread_foreach (thread_action_func *func, void *aux)
{
  struct list_elem *e;

  ASSERT (intr_get_level () == INTR_OFF);

  for (e = list_begin (&all_list); e != list_end (&all_list);
       e = list_next (e))
    {
      struct thread *t = list_entry (e, struct thread, allelem);
      func (t, aux);
}
```
aux就是传给这个函数的参数。  
然后， 给thread添加一个方法blocked_thread_check即可。并在thread.h中声明
```
/* Check the blocked thread */
void
blocked_thread_check (struct thread *t, void *aux UNUSED)
{
  if (t->status == THREAD_BLOCKED && t->ticks_blocked > 0)
  {
      t->ticks_blocked--;
      if (t->ticks_blocked == 0)
      {
          thread_unblock(t);
      }
  }
}
```
thread_unblock的作用就是把线程丢到就绪队列里继续跑  
```
/* Transitions a blocked thread T to the ready-to-run state.
   This is an error if T is not blocked.  (Use thread_yield() to
   make the running thread ready.)

   This function does not preempt the running thread.  This can
   be important: if the caller had disabled interrupts itself,
   it may expect that it can atomically unblock a thread and
   update other data. */
void
thread_unblock (struct thread *t)
{
  enum intr_level old_level;

  ASSERT (is_thread (t));

  old_level = intr_disable ();
  ASSERT (t->status == THREAD_BLOCKED);
  list_push_back (&ready_list, &t->elem);
  t->status = THREAD_READY;
  intr_set_level (old_level);
}
```
这样timer_sleep函数唤醒机制就实现了。

1.5实验结果
---
![image text](https://github.com/ToTkr2/Pintos1/blob/master/img/4.png)

问题2:
---
2.1实验背景与要求：
---
在pintos中排队优先级的问题  
在就绪列表中，当加入一个高优先级的线程，当前的线程应立即让出CPU的使用权。同样的，当线程在等待锁，信号量，条件变量的时候，队列中最高优先级的线程应该最先被唤醒。线程优先级在任何时候都可能发生变动，但是降低优先级可能会让该线程立即放弃CPU的使用权。  

2.2实现函数：
---
线程优先权从PRI_MIN(0)到PRI_MAX(63)，默认PRI_DEFAULT(31)。  

需要解决的第一个问题，是优先权倒置，高优先级先于低优先级执行，但是当高优先级所需要的锁被低优先级占用时，会产生死锁。一方面，高优先级需要低优先级的锁释放；另一方面，低优先级会在高优先级之后执行，所以产生相互等待。  

所以需要实行优先级捐赠，如果出现高优先级等待低优先级锁的情况，需要将高优先级的优先权捐赠给低的，当锁释放后，再撤销优先级更改。  

```
struct thread
  {
    /* Owned by thread.c. */
    tid_t tid;                          /* Thread identifier. */
    enum thread_status status;          /* Thread state. */
    char name[16];                      /* Name (for debugging purposes). */
    uint8_t *stack;                     /* Saved stack pointer. */
    int priority;                       /* Priority. */
    struct list_elem allelem;           /* List element for all threads list. */

    /* Shared between thread.c and synch.c. */
    struct list_elem elem;              /* List element. */

#ifdef USERPROG
    /* Owned by userprog/process.c. */
    uint32_t *pagedir;                  /* Page directory. */
#endif

    /* Owned by thread.c. */
    unsigned magic;                     /* Detects stack overflow. */

    /* Record the time the thread has been blocked. */
    int64_t ticks_blocked;
  };
```
可以看到每个线程有一个priority属性。  
这个属性值的约束我们在实验要求中已经找到，共64级（0-63），低数字对应低优先级，默认等级31。  
我们主要实验方法就是，使就绪队列是一个优先级队列，当插入一个新的线程时候，需要先排列优先级，然后每次从队头取。那么我们开始寻找可以将线程放入队列的函数，有如下：  
1. thread_unblock  
2. init_thread  
3. thread_yield  
在函数中，是如何实现将线程放入队列的。  
list_push_back (&ready_list, &t->elem);  
可见是将新加入的线程放入了队尾，我们来看pintos中的队列  
```
/* List element. */
struct list_elem 
  {
    struct list_elem *prev;     /* Previous list element. */
    struct list_elem *next;     /* Next list element. */
  };

/* List. */
struct list 
  {
    struct list_elem head;      /* List head. */
    struct list_elem tail;      /* List tail. */
  };
```
可以看到，有一个链表式的队列，还有队头和队尾指针。  
插入/排序的函数：  
```
/* Operations on lists with ordered elements. */
void list_sort (struct list *,
                list_less_func *, void *aux);
void list_insert_ordered (struct list *, struct list_elem *,
                          list_less_func *, void *aux);
void list_unique (struct list *, struct list *duplicates,
                  list_less_func *, void *aux);
```
insert_ordered的方法内容  
```
/* Inserts ELEM in the proper position in LIST, which must be
   sorted according to LESS given auxiliary data AUX.
   Runs in O(n) average case in the number of elements in LIST. */
void
list_insert_ordered (struct list *list, struct list_elem *elem,
                     list_less_func *less, void *aux)
{
  struct list_elem *e;

  ASSERT (list != NULL);
  ASSERT (elem != NULL);
  ASSERT (less != NULL);

  for (e = list_begin (list); e != list_end (list); e = list_next (e))
    if (less (elem, e, aux))
      break;
  return list_insert (e, elem);
}
```
它实现了按顺序插入到队列的功能。  


所以将：pushback语句  
list_push_back (&ready_list, &t->elem);  
更换成  
list_insert_ordered   
实现比较优先级的函数  
```
/* priority compare function. */
bool
 thread_cmp_priority (const struct list_elem *a, const struct list_elem *b, void *aux UNUSED)
 {
   return list_entry(a, struct thread, elem)->priority > list_entry(b, struct thread, elem)->priority;
 }
 ```
修改init_thread()和thread_yield()方法  

先分析一下抢占式调度的测试， 其实就是在创建一个线程的时候， 如果线程高于当前线程就先执行创建的线程。  
然后下面这个测试是基于抢占式调度的基础之上做的测试：  
```
void test_priority_change (void) 
{
  /* This test does not work with the MLFQS. */
  ASSERT (!thread_mlfqs);

  msg ("Creating a high-priority thread 2.");
  thread_create ("thread 2", PRI_DEFAULT + 1, changing_thread, NULL);
  msg ("Thread 2 should have just lowered its priority.");
  thread_set_priority (PRI_DEFAULT - 2);
  msg ("Thread 2 should have just exited.");
}

static void
changing_thread (void *aux UNUSED) 
{
  msg ("Thread 2 now lowering priority.");
  thread_set_priority (PRI_DEFAULT - 1);
  msg ("Thread 2 exiting.");
}

```

测试线程(我们称为thread1)创建了一个PRI_DEFAULT+1优先级的内核线程thread2，然后由于thread2优先级高，  
所以线程执行直接切换到thread2， thread1阻塞， 然后thread2执行的时候调用的是changing_thread， 又把自身优先级调为PRI_DEFAULT-1,  
这个时候thread1的优先级就大于thread2了， 此时thread2阻塞于最后一个msg输出， 线程切换到thread1， 然后thread1又把自己优先级改成PRI_DEFAULT-2,  
这个时候thread2又高于thread1了， 所以执行thread2， 然后在输出thread1的msg， 于是整个过程就有了图中的测试输出结果。  
 
分析这个测试行为我们得出的结论就是： 在设置一个线程优先级要立即重新考虑所有线程执行顺序， 重新安排执行顺序。  
弄清楚思路实现其实就非常简单了， 直接在线程设置优先级的时候调用thread_yield即可， 这样就把当前线程重新丢到就绪队列中继续执行，保证了执行顺序。  
此外， 还有在创建线程的时候， 如果新创建的线程比主线程优先级高的话也要调用thread_yield。  
```
/* Sets the current thread's priority to NEW_PRIORITY. */
void thread_set_priority (int new_priority)
{
  thread_current ()->priority = new_priority;
  thread_yield ();
}

```
2.3测试结果1：
---
![image text](https://github.com/ToTkr2/Pintos1/blob/master/img/3.png)  

下面研究inversion和donate priority的方法  
查看一下priority_donate_one  

```
void
test_priority_donate_one (void) 
{
  struct lock lock;

  /* This test does not work with the MLFQS. */
  ASSERT (!thread_mlfqs);

  /* Make sure our priority is the default. */
  ASSERT (thread_get_priority () == PRI_DEFAULT);

  lock_init (&lock);
  lock_acquire (&lock);
  thread_create ("acquire1", PRI_DEFAULT + 1, acquire1_thread_func, &lock);
  msg ("This thread should have priority %d.  Actual priority: %d.",
       PRI_DEFAULT + 1, thread_get_priority ());
  thread_create ("acquire2", PRI_DEFAULT + 2, acquire2_thread_func, &lock);
  msg ("This thread should have priority %d.  Actual priority: %d.",
       PRI_DEFAULT + 2, thread_get_priority ());
  lock_release (&lock);
  msg ("acquire2, acquire1 must already have finished, in that order.");
  msg ("This should be the last line before finishing this test.");
}

static void
acquire1_thread_func (void *lock_) 
{
  struct lock *lock = lock_;

  lock_acquire (lock);
  msg ("acquire1: got the lock");
  lock_release (lock);
  msg ("acquire1: done");
}

static void
acquire2_thread_func (void *lock_) 
{
  struct lock *lock = lock_;

  lock_acquire (lock);
  msg ("acquire2: got the lock");
  lock_release (lock);
  msg ("acquire2: done");
}

创建一个优先级高的线程acquire1（高于original线程，优先级default），那么此时acquire1会抢占锁。
/* Acquires LOCK, sleeping until it becomes available if
   necessary.  The lock must not already be held by the current
   thread.

   This function may sleep, so it must not be called within an
   interrupt handler.  This function may be called with
   interrupts disabled, but interrupts will be turned back on if
   we need to sleep. */
void
lock_acquire (struct lock *lock)
{
  ASSERT (lock != NULL);
  ASSERT (!intr_context ());
  ASSERT (!lock_held_by_current_thread (lock));

  sema_down (&lock->semaphore);
  lock->holder = thread_current ();
}
```



sema_down的P操作  
```
/* Down or "P" operation on a semaphore.  Waits for SEMA's value
   to become positive and then atomically decrements it.

   This function may sleep, so it must not be called within an
   interrupt handler.  This function may be called with
   interrupts disabled, but if it sleeps then the next scheduled
   thread will probably turn interrupts back on. */
void
sema_down (struct semaphore *sema) 
{
  enum intr_level old_level;

  ASSERT (sema != NULL);
  ASSERT (!intr_context ());

  old_level = intr_disable ();
  while (sema->value == 0) 
    {
      list_push_back (&sema->waiters, &thread_current ()->elem);
      thread_block ();
    }
  sema->value--;
  intr_set_level (old_level);
}
```
这里acquire1_thread_func阻塞了， msg这个时候并不会输出， 这时会继续执行original_thread, 然后输出msg， 输出当前线程应该的优先级和实际的优先级。  
然后继续创建一个线程acquire2, 优先级为PRI_DEFAULT+2， 这里调用和acquire1一致， 然后original_thread继续输出msg。  
 然后original_thread释放了这个锁（V操作）， 释放的过程会触发被锁着的线程acquire1, acquire2， 然后根据优先级调度， 先执行acquire2, 再acquire1, 最后再执行original_thread。  
那么这里应该是acquire2, acquire1分别释放锁然后输出msg， 最后original_thread再输出msg。  


看来一下希望的输出结果  
```
# -*- perl -*-  
use strict;
use warnings;
use tests::tests;
check_expected ([<<'EOF']);
(priority-donate-one) begin
(priority-donate-one) This thread should have priority 32.  Actual priority: 32.
(priority-donate-one) This thread should have priority 33.  Actual priority: 33.
(priority-donate-one) acquire2: got the lock
(priority-donate-one) acquire2: done
(priority-donate-one) acquire1: got the lock
(priority-donate-one) acquire1: done
(priority-donate-one) acquire2, acquire1 must already have finished, in that order.
(priority-donate-one) This should be the last line before finishing this test.
(priority-donate-one) end
EOF
pass;
```
original_thread拥有的锁被acquire1获取之后， 因为acquire1线程被阻塞于这个锁， 那么acquire1的执行必须要original_thread继续执行释放这个锁， 从优先级的角度来说， original_thread的优先级应该提升到acquire1的优先级,因为original_thread本身的执行包含了acquire1执行的阻塞， 所以此时acquire1对original_thread做了捐赠， 优先级提到PRI_DEFAULT+1， acquire2行为类似。    
 
支持priority-donate-one分析结束，分析：  
具体行为被锁定在了锁的获取和释放上了， 我们的实现思路是：  
在一个线程获取一个锁的时候， 如果拥有这个锁的线程优先级比自己低就提高它的优先级，然后在这个线程释放掉这个锁之后把原来拥有这个锁的线程改回原来的优先级。  
```
priority_donate_multiple:
void
test_priority_donate_multiple (void) 
{
  struct lock a, b;

  /* This test does not work with the MLFQS. */
  ASSERT (!thread_mlfqs);

  /* Make sure our priority is the default. */
  ASSERT (thread_get_priority () == PRI_DEFAULT);

  lock_init (&a);
  lock_init (&b);

  lock_acquire (&a);
  lock_acquire (&b);

  thread_create ("a", PRI_DEFAULT + 1, a_thread_func, &a);
  msg ("Main thread should have priority %d.  Actual priority: %d.",
       PRI_DEFAULT + 1, thread_get_priority ());

  thread_create ("b", PRI_DEFAULT + 2, b_thread_func, &b);
  msg ("Main thread should have priority %d.  Actual priority: %d.",
       PRI_DEFAULT + 2, thread_get_priority ());

  lock_release (&b);
  msg ("Thread b should have just finished.");
  msg ("Main thread should have priority %d.  Actual priority: %d.",
       PRI_DEFAULT + 1, thread_get_priority ());

  lock_release (&a);
  msg ("Thread a should have just finished.");
  msg ("Main thread should have priority %d.  Actual priority: %d.",
       PRI_DEFAULT, thread_get_priority ());
}

static void
a_thread_func (void *lock_) 
{
  struct lock *lock = lock_;

  lock_acquire (lock);
  msg ("Thread a acquired lock a.");
  lock_release (lock);
  msg ("Thread a finished.");
}

static void
b_thread_func (void *lock_) 
{
  struct lock *lock = lock_;

  lock_acquire (lock);
  msg ("Thread b acquired lock b.");
  lock_release (lock);
  msg ("Thread b finished.");
}


priority_donate_nest:
void
test_priority_donate_nest (void) 
{
  struct lock a, b;
  struct locks locks;

  /* This test does not work with the MLFQS. */
  ASSERT (!thread_mlfqs);

  /* Make sure our priority is the default. */
  ASSERT (thread_get_priority () == PRI_DEFAULT);

  lock_init (&a);
  lock_init (&b);

  lock_acquire (&a);

  locks.a = &a;
  locks.b = &b;
  thread_create ("medium", PRI_DEFAULT + 1, medium_thread_func, &locks);
  thread_yield ();
  msg ("Low thread should have priority %d.  Actual priority: %d.",
       PRI_DEFAULT + 1, thread_get_priority ());

  thread_create ("high", PRI_DEFAULT + 2, high_thread_func, &b);
  thread_yield ();
  msg ("Low thread should have priority %d.  Actual priority: %d.",
       PRI_DEFAULT + 2, thread_get_priority ());

  lock_release (&a);
  thread_yield ();
  msg ("Medium thread should just have finished.");
  msg ("Low thread should have priority %d.  Actual priority: %d.",
       PRI_DEFAULT, thread_get_priority ());
}

static void
medium_thread_func (void *locks_) 
{
  struct locks *locks = locks_;

  lock_acquire (locks->b);
  lock_acquire (locks->a);

  msg ("Medium thread should have priority %d.  Actual priority: %d.",
       PRI_DEFAULT + 2, thread_get_priority ());
  msg ("Medium thread got the lock.");

  lock_release (locks->a);
  thread_yield ();

  lock_release (locks->b);
  thread_yield ();

  msg ("High thread should have just finished.");
  msg ("Middle thread finished.");
}

static void
high_thread_func (void *lock_) 
{
  struct lock *lock = lock_;

  lock_acquire (lock);
  msg ("High thread got the lock.");
  lock_release (lock);
  msg ("High thread finished.");
}
```
medium 线程获取b锁，在获取a锁时阻塞了。  
original 线程优先级升高，优先输出。  
然后创建优先级为PRI_DEFAULT+2的high线程， 抢占调用high_thread_func， 然后这里high拿到了b这个锁， 而b的拥有者是medium， 阻塞， 注意， 这里medium被high捐赠了， 优先级到PRI_DEFAULT+2, 此时original_thread也应该一样提到同样优先级。  
然后original_thread输出一下优先级msg之后释放掉锁a， 释放出发了medium_thread_func抢占调用， 输出此时优先级为PRI_DEFAULT+2， 然后medium释放掉a, 释放掉b， 释放b的时候被high_thread_func抢占， high输出完之后medium继续run， 输出两句之后再到original_thread  

输出结果：  
```
# -*- perl -*-
use strict;
use warnings;
use tests::tests;
check_expected ([<<'EOF']);
(priority-donate-nest) begin
(priority-donate-nest) Low thread should have priority 32.  Actual priority: 32.
(priority-donate-nest) Low thread should have priority 33.  Actual priority: 33.
(priority-donate-nest) Medium thread should have priority 33.  Actual priority: 33.
(priority-donate-nest) Medium thread got the lock.
(priority-donate-nest) High thread got the lock.
(priority-donate-nest) High thread finished.
(priority-donate-nest) High thread should have just finished.
(priority-donate-nest) Middle thread finished.
(priority-donate-nest) Medium thread should just have finished.
(priority-donate-nest) Low thread should have priority 31.  Actual priority: 31.
(priority-donate-nest) end
EOF
pass;
```
这个测试是一个优先级嵌套问题， 重点在于medium拥有的锁被low阻塞， 在这个前提下high再去获取medium的说阻塞的话， 优先级提升具有连环效应， 就是medium被提升了， 此时它被锁捆绑的low线程应该跟着一起提升。  
 我们线程又需要加一个数据结构， 我们需要获取这个线程被锁于哪个线程。  
```
priority_donate_chain:
void
test_priority_donate_chain (void) 
{
  int i;  
  struct lock locks[NESTING_DEPTH - 1];
  struct lock_pair lock_pairs[NESTING_DEPTH];

  /* This test does not work with the MLFQS. */
  ASSERT (!thread_mlfqs);

  thread_set_priority (PRI_MIN);

  for (i = 0; i < NESTING_DEPTH - 1; i++)
    lock_init (&locks[i]);

  lock_acquire (&locks[0]);
  msg ("%s got lock.", thread_name ());

  for (i = 1; i < NESTING_DEPTH; i++)
    {
      char name[16];
      int thread_priority;

      snprintf (name, sizeof name, "thread %d", i);
      thread_priority = PRI_MIN + i * 3;
      lock_pairs[i].first = i < NESTING_DEPTH - 1 ? locks + i: NULL;
      lock_pairs[i].second = locks + i - 1;

      thread_create (name, thread_priority, donor_thread_func, lock_pairs + i);
      msg ("%s should have priority %d.  Actual priority: %d.",
          thread_name (), thread_priority, thread_get_priority ());

      snprintf (name, sizeof name, "interloper %d", i);
      thread_create (name, thread_priority - 1, interloper_thread_func, NULL);
    }

  lock_release (&locks[0]);
  msg ("%s finishing with priority %d.", thread_name (),
                                         thread_get_priority ());
}

static void
donor_thread_func (void *locks_) 
{
  struct lock_pair *locks = locks_;

  if (locks->first)
    lock_acquire (locks->first);

  lock_acquire (locks->second);
  msg ("%s got lock", thread_name ());

  lock_release (locks->second);
  msg ("%s should have priority %d. Actual priority: %d", 
        thread_name (), (NESTING_DEPTH - 1) * 3,
        thread_get_priority ());

  if (locks->first)
    lock_release (locks->first);

  msg ("%s finishing with priority %d.", thread_name (),
                                         thread_get_priority ());
}

static void
interloper_thread_func (void *arg_ UNUSED)
{
  msg ("%s finished.", thread_name ());
}
```
lock_pair是包含两个lock指针的结构体， 将当前线程优先级设为PRI_MIN， 此处locks数组 容量为7,  lock_pairs数组用来装lock_pair， 容量为7。  
当前线程获取locks[0]这个锁， 进入7次循环中， 每次循环thread_priority为PRI_MIN+i*3， 对应的lock_pairs[i]的first记录locks[i]的指针， second记录locks[i-1]指针，  
  
  
每次循环最后还创建了1个线程， 优先级为thread_priority-1， 但是由于上一个线程创建和阻塞的过程中优先级捐献已经发生， 所以这里并不发生抢占， 只是创建出来而已。  
然后original_thread释放掉locks[0]， 释放掉这个之后thread1得到了唤醒， 输出信息， 释放掉这个锁， 然后输出当前优先级， 由于这个线程还是被后面最高优先级的线程捐赠的，所以每次这里又触发下一个线程继续跑， 注意当后面的全部跑完的时候当前线程的优先级其实是不被捐赠的， 这里就变成了原来的优先级， 但是是所有线程都释放了之后才依次返回输出结束msg。  
这个测试其实就是一个链式优先级捐赠， 本质测试的还是多层优先级捐赠逻辑的正确性。  
需要注意的是一个逻辑： 释放掉一个锁之后， 如果当前线程不被捐赠即马上改为原来的优先级， 抢占式调度。  

1.一个线程所需要的锁被占用，且占用的进程比自己优先级低，那么就将自己的优先级捐赠给低优先级线程。如果出现多层占用多层锁，那么就递归捐赠。  
2. 一个线程被多个线程捐赠，维持被捐赠的最大优先级。  
3.对一个线程进行优先级设置的时候， 如果这个线程处于被捐赠状态， 则对original_priority进行设置， 然后如果设置的优先级大于当前优先级， 则改变当前优先级， 否则在捐赠状态取消的时候恢复original_priority。  
4. 在释放锁对一个锁优先级有改变的时候应考虑其余被捐赠优先级和当前优先级。  
5. 将信号量的等待队列实现为优先级队列。  
6.释放锁的时候若优先级改变则可以发生抢占。  

2.4具体代码实现：
---
先修改thread数据结构， 加入以下成员：  
```
1     int base_priority;                  /* Base priority. */
2     struct list locks;                  /* Locks that the thread is holding. */
3     struct lock *lock_waiting;          /* The lock that the thread is waiting for. */
```
给lock添加成员：  
```
1     struct list_elem elem;      /* List element for priority donation. */
2     int max_priority;          /* Max priority among the threads acquiring the lock. */
```
先修改lock_acquire函数：  
```
void lock_acquire (struct lock *lock)
{
  struct thread *current_thread = thread_current ();
  struct lock *l;
  enum intr_level old_level;

  ASSERT (lock != NULL);
  ASSERT (!intr_context ());
  ASSERT (!lock_held_by_current_thread (lock));

  if (lock->holder != NULL && !thread_mlfqs)
  {
    current_thread->lock_waiting = lock;
    l = lock;
    while (l && current_thread->priority > l->max_priority)
    {
      l->max_priority = current_thread->priority;
      thread_donate_priority (l->holder);
      l = l->holder->lock_waiting;
    }
  }

  sema_down (&lock->semaphore);

  old_level = intr_disable ();

  current_thread = thread_current ();
  if (!thread_mlfqs)
  {
    current_thread->lock_waiting = NULL;
    lock->max_priority = current_thread->priority;
    thread_hold_the_lock (lock);
  }
  lock->holder = current_thread;

  intr_set_level (old_level);
}

```
```
/* Let thread hold a lock */
void
thread_hold_the_lock(struct lock *lock)
{
  enum intr_level old_level = intr_disable ();
  list_insert_ordered (&thread_current ()->locks, &lock->elem, lock_cmp_priority, NULL);

  if (lock->max_priority > thread_current ()->priority)
  {
    thread_current ()->priority = lock->max_priority;
    thread_yield ();
  }

  intr_set_level (old_level);
}
```
```
/* Donate current priority to thread t. */
void
thread_donate_priority (struct thread *t)
{
  enum intr_level old_level = intr_disable ();
  thread_update_priority (t);

  if (t->status == THREAD_READY)
  {
    list_remove (&t->elem);
    list_insert_ordered (&ready_list, &t->elem, thread_cmp_priority, NULL);
  }
  intr_set_level (old_level);
}
```
锁队列排序函数lock_cmp_priority:  
```
 /* lock comparation function */
 bool  lock_cmp_priority (const struct list_elem *a, const struct list_elem *b, void *aux UNUSED)
 {
   return list_entry (a, struct lock, elem)->max_priority > list_entry (b, struct lock, elem)->max_priority;
}
```
然后在lock_release函数加入以下语句：  
  ```
  if (!thread_mlfqs)
     thread_remove_lock (lock);
```
thread_remove_lock实现如下：  
```
/* Remove a lock. */
void thread_remove_lock (struct lock *lock)
{
  enum intr_level old_level = intr_disable ();
  list_remove (&lock->elem);
  thread_update_priority (thread_current ());
  intr_set_level (old_level);
}
```
当释放掉一个锁的时候， 当前线程的优先级可能发生变化， 我们用thread_update_priority来处理：
```
/* Update priority. */
void
thread_update_priority (struct thread *t)
{
  enum intr_level old_level = intr_disable ();
  int max_priority = t->base_priority;
  int lock_priority;

  if (!list_empty (&t->locks))
  {
    list_sort (&t->locks, lock_cmp_priority, NULL);
    lock_priority = list_entry (list_front (&t->locks), struct lock, elem)->max_priority;
    if (lock_priority > max_priority)
      max_priority = lock_priority;
  }

  t->priority = max_priority;
  intr_set_level (old_level);
}
```
在init_thread中加入初始化：  
```
  t->base_priority = priority;
  list_init (&t->locks);
  t->lock_waiting = NULL;
thread_set_priority：
void
thread_set_priority (int new_priority)
{
  if (thread_mlfqs)
    return;

  enum intr_level old_level = intr_disable ();

  struct thread *current_thread = thread_current ();
  int old_priority = current_thread->priority;
  current_thread->base_priority = new_priority;

  if (list_empty (&current_thread->locks) || new_priority > old_priority)
  {
    current_thread->priority = new_priority;
    thread_yield ();
  }

  intr_set_level (old_level);
}
```

把condition的队列改成优先级队列  
```
void cond_signal (struct condition *cond, struct lock *lock UNUSED)
{
  ASSERT (cond != NULL);
  ASSERT (lock != NULL);
  ASSERT (!intr_context ());
  ASSERT (lock_held_by_current_thread (lock));

  if (!list_empty (&cond->waiters))
  {
    list_sort (&cond->waiters, cond_sema_cmp_priority, NULL);
    sema_up (&list_entry (list_pop_front (&cond->waiters), struct semaphore_elem, elem)->semaphore);
  }
}
```
比较函数： 
```
/* cond sema comparation function */
bool
cond_sema_cmp_priority (const struct list_elem *a, const struct list_elem *b, void *aux UNUSED)
{
  struct semaphore_elem *sa = list_entry (a, struct semaphore_elem, elem);
  struct semaphore_elem *sb = list_entry (b, struct semaphore_elem, elem);
  return list_entry(list_front(&sa->semaphore.waiters), struct thread, elem)->priority > list_entry(list_front(&sb->semaphore.waiters), struct thread, elem)->priority;
}
```
把信号量的等待队列实现为优先级队列：sema_up和sema_down  
```

void sema_up (struct semaphore *sema)
{
  enum intr_level old_level;

  ASSERT (sema != NULL);

  old_level = intr_disable ();
  if (!list_empty (&sema->waiters))
  {
    list_sort (&sema->waiters, thread_cmp_priority, NULL);
    thread_unblock (list_entry (list_pop_front (&sema->waiters), struct thread, elem));
  }

  sema->value++;
  thread_yield ();
  intr_set_level (old_level);
}
—————-
void
sema_down (struct semaphore *sema)
{
  enum intr_level old_level;

  ASSERT (sema != NULL);
  ASSERT (!intr_context ());

  old_level = intr_disable ();
  while (sema->value == 0)
    {
      list_insert_ordered (&sema->waiters, &thread_current ()->elem, thread_cmp_priority, NULL);
      thread_block ();
    }
  sema->value--;
  intr_set_level (old_level);
}

```
2.5实验结果2
---
![image text](https://github.com/ToTkr2/Pintos1/blob/master/img/5.png)  



问题 3：多级反馈调度
---
3.1 问题描述
---

这里是维持了64个队列， 每个队列对应一个优先级， 从PRI_MIN到PRI_MAX。  
通过一些公式计算来计算出线程当前的优先级， 系统调度的时候会从高优先级队列开始选择线程执行， 这里线程的优先级随着操作系统的运转数据而动态改变。  
这个计算又涉及到了浮点数运算的问题， pintos本身并没有实现这个， 需要我们自己来实现。  

3.2 问题分析
---

3.2.1 进程的基本状态  
进程在其生命周期内，由于系统中各进程之间的相互制约关系及系统的运行环境的变化，使得进程的状态也在不断地发生变化(一个进程会经历若干种不同状态)。通常进程有以下五种状态  

![image text](https://github.com/ToTkr2/Pintos1/blob/master/img/1.png)  

 3.2.2 实现思路  
在timer_interrupt中固定一段时间计算更新线程的优先级，这里是每TIMER_FREQ时间更新一次系统load_avg和所有线程的recent_cpu， 每4个timer_ticks更新一次线程优先级， 每个timer_tick running线程的recent_cpu加一， 虽然这里说的是维持64个优先级队列调度， 其本质还是优先级调度， 我们保留之前写的优先级调度代码即可， 去掉优先级捐赠（之前donate相关代码已经对需要的地方加了thread_mlfqs的判断了）。  

3.2.3 算法描述  
1、多个就绪队列，优先级最高的是第一级队列  
2、第一级队列若为空，进入第二级队列调度  
3、各级队列均按照时间片轮转方式调度，其中不同就绪队列的进程分配长度不等的时间片，优先级越高，时间片越小。  
4、当进程的时间片用完时，进入下一级就绪队列  

3.3 实验步骤  
---

浮点运算逻辑实现在fixed_point.h中  

1、先实现timer_interrupt的逻辑，加入以下代码： 
```
if (thread_mlfqs)
  {
    thread_mlfqs_increase_recent_cpu_by_one ();
    if (ticks % TIMER_FREQ == 0)
      thread_mlfqs_update_load_avg_and_recent_cpu ();
    else if (ticks % 4 == 0)
      thread_mlfqs_update_priority (thread_current ());
  }
```
编写thread_mlfqs_increase_recent_cpu_by_one 函数，实现每个timer_tick running线程的recent_cpu加一的功能。  
```
/* Increase recent_cpu by 1. */
void
thread_mlfqs_increase_recent_cpu_by_one (void)
{
  ASSERT (thread_mlfqs);
  ASSERT (intr_context ());

  struct thread *current_thread = thread_current ();
  if (current_thread == idle_thread)
    return;
  current_thread->recent_cpu = FP_ADD_MIX (current_thread->recent_cpu, 1);
}
```
编写thread_mlfqs_update_load_avg_and_recent_cpu 函数，实现每TIMER_FREQ时间更新一次系统load_avg和所有线程的recent_cpu的功能，这里的大部分逻辑都是Project给好的算数运算逻辑。  
```
/* Every per second to refresh load_avg and recent_cpu of all threads. */
void
thread_mlfqs_update_load_avg_and_recent_cpu (void)
{
  ASSERT (thread_mlfqs);
  ASSERT (intr_context ());
  size_t ready_threads = list_size (&ready_list);
  if (thread_current () != idle_thread)
    ready_threads++;
  load_avg = FP_ADD (FP_DIV_MIX (FP_MULT_MIX (load_avg, 59), 60), FP_DIV_MIX (FP_CONST (ready_threads), 60));
struct thread *t;
  struct list_elem *e = list_begin (&all_list);
  for (; e != list_end (&all_list); e = list_next (e))
  {
    t = list_entry(e, struct thread, allelem);
    if (t != idle_thread)
    {
      t->recent_cpu = FP_ADD_MIX (FP_MULT (FP_DIV (FP_MULT_MIX (load_avg, 2), FP_ADD_MIX (FP_MULT_MIX (load_avg, 2), 1)), t->recent_cpu), t->nice);
      thread_mlfqs_update_priority (t);
    }
  }
}
```
编写thread_mlfqs_update_priority函数，实现每4个timer_ticks更新一次线程优先级的功能。  
```
/* Update priority. */
void
thread_mlfqs_update_priority (struct thread *t)
{
  if (t == idle_thread)
    return;
  ASSERT (thread_mlfqs);
  ASSERT (t != idle_thread);
  t->priority = FP_INT_PART (FP_SUB_MIX (FP_SUB (FP_CONST (PRI_MAX), FP_DIV_MIX (t->recent_cpu, 4)), 2 * t->nice));
  t->priority = t->priority < PRI_MIN ? PRI_MIN : t->priority;
  t->priority = t->priority > PRI_MAX ? PRI_MAX : t->priority;
}
```
此时，mission3的主体逻辑就已经完成了。接下来修改thread结构体，加入新成员  
```
int nice;                           /* Niceness. */
fixed_t recent_cpu;                 /* Recent CPU. */
```
然后在init_thread中加入代码。使得在线程初始化的时候初始化新的成员。  
```
t->nice = 0;
t->recent_cpu = FP_CONST (0);
```
最后编写一些对应函数完成必要的计算  
```
/* Sets the current thread's nice value to NICE. */
void
thread_set_nice (int nice)
{
  thread_current ()->nice = nice;
  thread_mlfqs_update_priority (thread_current ());
  thread_yield ();
}
/* Returns the current thread's nice value. */
int
thread_get_nice (void)
{
  return thread_current ()->nice;
}
/* Returns 100 times the system load average. */
int
thread_get_load_avg (void)
{
  return FP_ROUND (FP_MULT_MIX (load_avg, 100));
}
/* Returns 100 times the current thread's recent_cpu value. */
int
thread_get_recent_cpu (void)
{
  return FP_ROUND (FP_MULT_MIX (thread_current ()->recent_cpu, 100));
}
```
最后在thread.c中加入全局变量：  
fixed_t load_avg;  
并在thread_start中初始化  
load_avg = FP_CONST (0);  

3.4 实验结果
---
![image text](https://github.com/ToTkr2/Pintos1/blob/master/img/2.png)  


本文参考https://www.cnblogs.com/laiy/p/pintos_project1_thread.html  
